
---
目录：[[AI 全栈技术树（AI Full-Stack Tech Tree）【2026版】]]
上一页：
下一页：
关键词：
相关链接：

---


### [[概念术语：KG（Knowledge Graph，知识图谱）]]

### [[概念术语：AI Copilot（AI 助手应用工具）]]

### [[概念术语：SaaS （Software as a Service，软件即服务）]]



### [[概念术语：AI Prompt Engineering（AI  提示词工程）]]

### [[概念术语：Reasoning Model（推理模型）]]

### 幻觉（Hallucination）成因

### 对齐（Alignment）与偏差

### 向量化（Embedding）

### 切片与清洗


### 机器学习

### 深度学习：是机器学习(ML) 的子集

### 神经网络

### 神经卷积

### 自然语言处理

### 计算机视觉

### 自然语言生成技术（NLG）


---

### ASIC (Application-Specific Integrated Circuit)

AI芯片定义为“专门针对AI算法做了特殊加速设计的芯片”。

在AI芯片领域，GPU既面临ASIC（如谷歌TPU）在特定场景的性能优势竞争。

GPU因为不是专门针对AI算法开发的ASIC，执行AI计算的速度优势还没到极限，还有提升空间。所以GPU不是适合智能驾驶的最佳AI芯片选择。因此开发ASIC就成了必然。

使用GPU、FPGA等已有的通用芯片可以避免专门研发定制芯片（ASIC）的高投入和高风险。


### FPGA (Field-Programmable Gate Array)

提供了高度的彈性，適合產品原型開發、小批量客製化以及需要快速迭代的應用。
目前通用的CPU、GPU、FPGA等都能执行AI算法，只是执行效率差异较大。


---

### 大语言模型（LLM）

### 多模态

### 多模态神经语言模型（如CLIP）

### 图像去噪扩散模型（Diffusion）

### AI智能体（AI Agent）


---

### 虚拟数字人


---


# LLM

大语言模型（LLM）是一种利用机器学习技术来理解和生成人类语言的人工智能模型。能够执行文本分析、情绪分析、语言翻译和语音识别等任务

大型语言模型(LLM) 是一种人工智能(AI) 程序，它可以识别和生成文本以及完成其他任务。 LLM 经过了庞大的数据集的训练，因此称之为“大型”。 LLM 在机器学习的基础上构建：具体来说，它是一种称为Transformer 模型的神经网络。

客户服务：LLM 可用于支持各行各业的客户服务，如聊天机器人或对话AI。 营销：市场营销团队可以使用LLM 来执行情感分析，以快速生成营销活动创意或文本等，作为推介示例。 法律：从搜索海量文本数据集到生成法律术语，大型语言模型可以为律师、律师助理和法律工作者提供帮助。 银行业：LLM 可以帮助信用卡公司检测欺诈行为。

# 什么是LLM微调？

LLM (大型语言模型) 微调是近年来 NLP (自然语言处理) 领域发展迅猛的一项技术，通过在预训练模型的基础上进行进一步训练，使模型能够学习特定领域或任务相关的知识，从而显著提升其在该领域或任务上的性能

# 什么是AIGC？

AIGC 又称生成式AI (Generative AI)，是继专业生产内容（PGC， Professional-generated Content）、用户生产内容（UGC， User-generated Content）之后的新型内容创作方式，可以在对话、故事、图像、视频和音乐制作等方面，打造新的数字内容生成与交互形式

AIGC和ChatGPT是两种不同的人工智能技术，分别代表了内容生成和智能对话的新趋势。

![AI学习](https://repo.in4tree.com/2026/01/15_1768521980712.png)

[https://www.51cto.com/article/759747.html](https://www.51cto.com/article/759747.html)

**Llama**

这是一个基础的LLM，由Facebook（现在的Meta）创建，并将其作为其所宣称的”对开放科学的承诺“的一部分而发布出来。任何人都可以下载Llama并将其作为创建更精细调整模型的基础，用于特定应用程序（Alpaca和Vicuna都是基于Llama构建的）。该模型还提供四种不同规模的版本。较小的版本只有70亿个参数，已经在意想不到的地方使用。甚至有一位开发者声称已经使用只有4GB RAM的Llama在Raspberry Pi上运行。

**Alpaca**

一些斯坦福大学的研究人员使用Meta的Llama 7B，并将其训练成了一组与ChatGPT等指令遵循模型相似的提示。这个微调过程产生了Alpaca 7B，这个模型让普通人也可以通过提问和给予指示来获取Llama LLM中编码的知识。据估计，这种轻量级LLM可以在不到600美元的硬件上运行。

Alpaca 7B的创建者正在分发训练集和构建它的代码，任何人都可以复制该模型或基于不同数据集创建新模型。

**Vicuna**

Llama的另一个”后裔“是来自LMSYS.org的Vicuna。Vicuna团队收集了来自ShareGPT的70,000个不同对话的训练集，并特别关注创建多轮交互和指令遵循能力。Vicuna提供Vicuna-13b或Vicuna-7b两个版本，它是基本交互式聊天中价格竞争最激烈的开放解决方案之一。

**NodePad**

并非所有人都对LLMs生成的“语言准确”的文本感到着迷。NodePad的创建者认为，文本质量往往会分散用户注意力，使其无法仔细检查底层事实。具有良好用户界面的LLMs“往往无意中会美化结果，使用户更难以判断这些问题。”NodePad旨在培养探索和构思的能力，而不是产生用户只会草率浏览的完美写作样本。这个LLM生成的结果呈现为节点和连接，就像许多“思维导图工具”中所见，而不像成品写作。用户可以利用模型的百科全书知识来获得伟大的创意，而不会陷入演示中迷失方向。

**Orca**

第一代大规模语言模型通过增加规模不断取得成功。然而，微软团队的研究人员开发的Orca模型打破了这种趋势。该模型仅使用了130亿个参数，使其能够在普通计算机上运行。Orca的开发者通过改进训练算法来使用“解释轨迹”、“逐步思考过程”和“指令”来实现这一壮举。与其只要求AI从原始材料中学习不同，Orca被赋予了一个旨在进行教学的训练集。换句话说，就像人类一样，当AI不被投入到深水区时，它们学习得更快。初步结果很有希望，微软团队提供了基准测试数据，表明该模型的性能与规模更大的模型相当。

**Jasper**

Jasper的创建者不想构建一个无所不知的模型，他们想要一个专注于内容创作的模型。系统并非仅提供无限制的聊天会话，而是提供了50多个针对特定任务设计的模板，例如撰写房地产列表或为亚马逊等网站编写产品特点。付费版本专门面向希望以一致语调创建营销文案的企业。

**Claude**

Anthropic创建了Claude，旨在成为一个有用的助手，可以处理企业的许多基于文本的任务，包括研究和客户服务等。输入一个提示，输出一个答案。Anthropic特意允许长提示，以鼓励更复杂的指令，使用户对结果拥有更多控制权。Anthropic目前提供两个版本：名为Claude-v1的完整模型和更便宜、简化的版本Claude Instant，后者价格显著较低。前者适用于需要更复杂、结构化推理的工作，而后者在分类和审查等简单任务中速度更快、效果更好。

**Cerebras**

当专用硬件和通用模型共同演化时，您可以获得非常快速和高效的解决方案。Cerebras在Hugging Face上提供其LLM的各种规模，从小型（1.11亿个参数）到大型（130亿个参数），供那些想要在本地运行它的用户选择。然而，许多人可能希望使用云服务，这些云服务在Cerebras自己的芯片级集成处理器上运行，该处理器经过优化，可以高效处理大规模训练集。

**Falcon**

United Arab Emirates的科技创新研究院（Technology Innovation Institute，简称TII）开发了全尺寸的Falcon-40b和较小的Falcon-7b模型。他们使用来自RefinedWeb的大量通用实例对Falcon模型进行训练，重点改善了推理能力。然后，他们选择以Apache 2.0许可证发布该模型，使其成为最开放的可供实验无限制使用的模型之一。

**ImageBind**

许多人认为Meta是一家主导社交媒体的大公司，但它也是开源软件开发领域的强大力量。现在人们对人工智能的兴趣正在蓬勃发展，所以公司开始分享自己的许多创新并不令人意外。ImageBind是一个旨在展示人工智能如何同时创建多种不同类型数据的项目，包括文本、音频和视频。换句话说，生成式人工智能可以将整个想象世界拼接在一起，只要你允许它这样做。

**Gorilla**

你可能已经听说过使用生成式人工智能来编写代码的方法。结果在表面上看起来令人印象深刻，但仔细检查后会发现存在深层次的缺陷。语法可能是正确的，但API调用都是错误的，甚至可能指向不存在的函数。Gorilla是一个旨在更好地处理编程接口的LLM。它的创建者从Llama开始，然后针对直接从文档中获取的更深入的编程细节进行了微调。Gorilla团队还提供了自己基于API的一系列测试指标以测试成功率。这对于寻求依靠AI进行编码辅助的程序员来说是一个重要的补充。

**Ora.ai**

Ora是一个允许用户创建针对特定任务进行优化的定制聊天机器人。LibrarianGPT将尝试使用书中的直接段落回答任何问题。例如，卡尔·萨根教授是一个机器人，可以引用萨根的所有著作，使他可以生活在数十亿年的时间里。您可以创建自己的机器人，也可以使用其他人已经创建的数百个机器人之一。

**AgentGPT**

AgentGPT是另一个将应用程序所需的所有代码拼接在一起的工具。它旨在创建可以处理诸如规划度假或编写某种类型游戏代码等工作的代理。技术堆栈的许多源代码都可在GPL 3.0下获得。还提供了作为服务运行的版本。

**FrugalGPT**

FrugalGPT并不是一种不同的模型，而是一种寻找回答特定问题最便宜的模型的策略。开发FrugalGPT的研究人员认识到，许多问题并不需要最大、最昂贵的模型。他们的算法从最简单的模型开始，并按照级联的方式逐步选择更复杂的语言模型，直到找到一个合适的答案。

FrugalGPT旨在通过为每个具体问题选择最合适的模型来优化资源使用，从而在不降低准确性和效果的情况下降低成本。研究人员的实验证明，这种谨慎的方法可能节省高达98%的成本，因为许多问题实际上并不需要复杂的模型

除了耳熟能详的 OpenAI GPT 系列外，还有GLM、Bloom、Bard、Bert、LaMDa、LLaMA 等出自其他人工智能公司的大语言模型，它们听起来功能相似，但却各具特色，拥有自己独特的用户群。这些大语言模型正在彻底改变我们与技术互动的方式，塑造一个与机器交流就像与朋友聊天一样自然的未来。从生成创意内容到协助高级研究，大语言模型正在融入我们的日常生活。

所有这些大模型都基于 Transformer 工作。Transformer 是一种神经网络架构，通过分析文本中单词和短语之间的关系，使计算机能够理解、解释和生成人类语言。与以往按顺序处理语言的模型不同，Transformer 可以同时处理多个句子部分。现在，让这个想法变得更加贴近生活：想象一下，在阅读一本书时，我们可以同时理解书中所有的人物、情节转折和情感，而不是逐字逐句地理解。Transformer 对语言也有类似的处理方式，他们能迅速理解文字背后的含义。这种处理语言的独特方式使 Transformer 成为强大计算机程序的基础，这些程序可以用听起来像人一样的方式聊天、写作和思考。

作者：YBCarry_段松啓  
链接：https://juejin.cn/post/7313728275787579432  
来源：稀土掘金  
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

---

### AI大模型里经常提到的“炼丹”、“挖矿”、“蒸馏”

-  炼丹：这是一个来自中国的网络用语，原意是道教中的炼金术，用来寻求长生不老的药丹。在机器学习领域。指训练大规模的神经网络模型，特别是预训练语言模型，如GPT、BERT等。这个过程需要大呈的数据、算力和技巧，就像炼制灵丹一样。炼丹重点描述模型调优的过程。这个过程往往需要大量的尝试和经验，包括选择合适的模型结构、优化算法、损失函数、学习率等，就像炼丹一样需要精细的操作和耐心的等待。
- 挖矿：在机器学习中，“挖矿"通常指的是数据挖掘，即从大是的、未经过处理的数据中提取有用信息和知识的过程。这个过程包括数据清洗、数据转换、数据分析、模式识别等步骤。在深度学习中，“挖矿"也可以指硬件的使用，比如使用GPU进行模型的训练,这个过程因为其高能耗和高计算需求，被比喻为"挖矿”。从大是的无标注数据中挖掘出有用的信息或知识。例如构建知识图谱、生成对话数据等。这个过程需要利用自然语言处理、机器学习等方法，就像开采矿藏一样。
- 蒸馏：模型蒸馏是一种模型压缩技术，它的目标是将一个大型、复杂的模型（被称为教师模型）的知识转移到一个小型、简单的模型（被称为学生模型）中。这个过程就像蒸馏一样，通过提取教师模型的关键信息（例如，它对数据的预测概率分布），并将这些信息用于训练学生模型，从而使学生模型能够模仿教师模型的行为，达到减小模型大小和计算复杂度的目的，同时保持较高的性能。

### 为什么用显卡跑图叫炼丹? 

一般炼丹指的是喂图出模型，不过跑图也是一样：提示词——咒语，咒语一念显示器（盖子）一关，显卡（丹炉）开始工作。  
耗时长，费电又产热和火炉子一样，所以被戏称为炼丹。

因为大部分人训练机器学习没什么技术含量，就是导入开源库然后找数据集训练。  
耗费大量的时间 物力 电力，中间能做的就是一遍遍调参，从0.1调成0.2这种。  
准确度全都随缘。就被戏称为炼丹

因为没法预料结果 全靠调参玄学